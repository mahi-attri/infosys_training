{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc7635-5763-4744-a150-40f1b628e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flask ultralytics easyocr mysql-connector-python opencv-python pandas\n",
    "from flask import Flask, request, jsonify, render_template, session, redirect, url_for\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from werkzeug.utils import secure_filename\n",
    "import shutil\n",
    "import uuid\n",
    "import json\n",
    "from datetime import datetime\n",
    "import difflib\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = os.urandom(24)\n",
    "app.config['UPLOAD_FOLDER'] = 'uploads/'\n",
    "app.config['PROCESSED_FOLDER'] = 'processed/'\n",
    "app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB max upload\n",
    "\n",
    "# Ensure upload directories exist\n",
    "os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)\n",
    "os.makedirs(app.config['PROCESSED_FOLDER'], exist_ok=True)\n",
    "\n",
    "\n",
    "# Load models directly from their paths\n",
    "classification_model = YOLO(r\"C:\\Users\\mahia\\OneDrive\\Desktop\\infosys_project\\classification_model\\yolo11n-cls.pt\")  # Load classification model\n",
    "detection_model = YOLO(r\"C:\\Users\\mahia\\OneDrive\\Desktop\\infosys_project\\detection_model\\yolo11n.pt\")  # Load detection model\n",
    "ocr_reader = easyocr.Reader(['en'])  # Load OCR model\n",
    "\n",
    "\n",
    "# Database configuration\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'aadhaar_user',\n",
    "    'password': 'aadhaar_password',\n",
    "    'database': 'aadhaar_fraud_db'\n",
    "}\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"Create a connection to the MySQL database\"\"\"\n",
    "    return mysql.connector.connect(**db_config)\n",
    "\n",
    "def calculate_similarity(str1, str2):\n",
    "    \"\"\"Calculate string similarity using difflib SequenceMatcher\"\"\"\n",
    "    if not str1 or not str2:\n",
    "        return 0\n",
    "    \n",
    "    str1 = str(str1).lower().strip()\n",
    "    str2 = str(str2).lower().strip()\n",
    "    \n",
    "    similarity = difflib.SequenceMatcher(None, str1, str2).ratio()\n",
    "    return round(similarity * 100, 2)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    \"\"\"Render the home page\"\"\"\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_files():\n",
    "    \"\"\"Handle file uploads (ZIP and Excel)\"\"\"\n",
    "    if 'zipfile' not in request.files or 'excelfile' not in request.files:\n",
    "        return jsonify({\"error\": \"Both ZIP and Excel files are required\"}), 400\n",
    "    \n",
    "    zip_file = request.files['zipfile']\n",
    "    excel_file = request.files['excelfile']\n",
    "    \n",
    "    if zip_file.filename == '' or excel_file.filename == '':\n",
    "        return jsonify({\"error\": \"No file selected\"}), 400\n",
    "    \n",
    "    # Create a unique session ID for this processing batch\n",
    "    session_id = str(uuid.uuid4())\n",
    "    session['current_session'] = session_id\n",
    "    \n",
    "    # Create directories for this session\n",
    "    session_upload_dir = os.path.join(app.config['UPLOAD_FOLDER'], session_id)\n",
    "    session_processed_dir = os.path.join(app.config['PROCESSED_FOLDER'], session_id)\n",
    "    \n",
    "    os.makedirs(session_upload_dir, exist_ok=True)\n",
    "    os.makedirs(session_processed_dir, exist_ok=True)\n",
    "    \n",
    "    # Save files\n",
    "    zip_path = os.path.join(session_upload_dir, secure_filename(zip_file.filename))\n",
    "    excel_path = os.path.join(session_upload_dir, secure_filename(excel_file.filename))\n",
    "    \n",
    "    zip_file.save(zip_path)\n",
    "    excel_file.save(excel_path)\n",
    "    \n",
    "    # Extract ZIP file\n",
    "    extract_dir = os.path.join(session_upload_dir, 'extracted')\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    \n",
    "    # Save paths to session\n",
    "    session['extract_dir'] = extract_dir\n",
    "    session['excel_path'] = excel_path\n",
    "    \n",
    "    return jsonify({\n",
    "        \"message\": \"Files uploaded successfully!\",\n",
    "        \"session_id\": session_id,\n",
    "        \"redirect\": url_for('process_page')\n",
    "    })\n",
    "\n",
    "@app.route('/process-page')\n",
    "def process_page():\n",
    "    \"\"\"Render the processing page\"\"\"\n",
    "    if 'current_session' not in session:\n",
    "        return redirect(url_for('home'))\n",
    "    \n",
    "    return render_template('process.html', session_id=session['current_session'])\n",
    "\n",
    "@app.route('/process', methods=['POST'])\n",
    "def process_files():\n",
    "    \"\"\"Process the uploaded files through the ML pipeline\"\"\"\n",
    "    if 'current_session' not in session:\n",
    "        return jsonify({\"error\": \"No active session\"}), 400\n",
    "    \n",
    "    extract_dir = session.get('extract_dir')\n",
    "    excel_path = session.get('excel_path')\n",
    "    \n",
    "    if not extract_dir or not excel_path:\n",
    "        return jsonify({\"error\": \"Upload files first\"}), 400\n",
    "    \n",
    "    # Read Excel file\n",
    "    try:\n",
    "        excel_data = pd.read_excel(excel_path)\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Error reading Excel file: {str(e)}\"}), 400\n",
    "    \n",
    "    # Get all images from extracted folder\n",
    "    image_files = []\n",
    "    for root, _, files in os.walk(extract_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # Process each image\n",
    "    results = []\n",
    "    \n",
    "    for image_path in image_files:\n",
    "        # 1. Classification - Check if it's an Aadhaar card\n",
    "        classification_result = classification_model(image_path)\n",
    "        is_aadhaar = classification_result[0].probs.top1  # Get the predicted class\n",
    "        \n",
    "        if is_aadhaar == 0:  # Assuming class 0 is \"Aadhaar\"\n",
    "            # 2. Detection - Detect fields in the Aadhaar card\n",
    "            detection_result = detection_model(image_path)\n",
    "            detected_fields = detection_result[0].boxes.data.tolist()  # Get detected fields\n",
    "            \n",
    "            # 3. OCR - Extract text from each field\n",
    "            extracted_data = {}\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            for field in detected_fields:\n",
    "                x1, y1, x2, y2, confidence, class_id = map(int, field[:6])\n",
    "                field_class = detection_model.names[class_id]  # Get class name (e.g., 'Name', 'UID', 'Address')\n",
    "                \n",
    "                # Crop the detected region\n",
    "                cropped_roi = image[y1:y2, x1:x2]\n",
    "                \n",
    "                # Convert cropped ROI to grayscale for OCR\n",
    "                gray_roi = cv2.cvtColor(cropped_roi, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Use EasyOCR to extract text\n",
    "                ocr_result = ocr_reader.readtext(gray_roi, detail=0)  # detail=0 returns only the text\n",
    "                text = ' '.join(ocr_result)  # Combine detected text if multiple lines\n",
    "                \n",
    "                # Save the text to the extracted_data dictionary\n",
    "                extracted_data[field_class] = text\n",
    "            \n",
    "            # 4. Match with Excel data\n",
    "            sr_match = None\n",
    "            for _, row in excel_data.iterrows():\n",
    "                # Match UID with Extracted UID\n",
    "                if 'uid' in extracted_data and str(row['UID']).strip() == str(extracted_data['uid']).strip():\n",
    "                    sr_match = row['SrNo']\n",
    "                    break\n",
    "                \n",
    "                # If UID not found or not clear, try matching name\n",
    "                if 'name' in extracted_data and calculate_similarity(row['Name'], extracted_data['name']) > 80:\n",
    "                    sr_match = row['SrNo']\n",
    "                    break\n",
    "            \n",
    "            if sr_match:\n",
    "                # Get corresponding row\n",
    "                record = excel_data[excel_data['SrNo'] == sr_match].iloc[0]\n",
    "                \n",
    "                # Calculate match scores\n",
    "                name_score = calculate_similarity(record['Name'], extracted_data.get('name', ''))\n",
    "                uid_score = calculate_similarity(str(record['UID']), extracted_data.get('uid', ''))\n",
    "                \n",
    "                # Extract address components\n",
    "                extracted_address = extracted_data.get('address', '')\n",
    "                \n",
    "                # Create address from Excel components\n",
    "                excel_address_parts = []\n",
    "                for field in ['House Flat Number', 'Town', 'Street Road Name', 'City', 'State', 'PINCODE']:\n",
    "                    if field in record and pd.notna(record[field]):\n",
    "                        excel_address_parts.append(str(record[field]))\n",
    "                \n",
    "                excel_address = \" \".join(excel_address_parts)\n",
    "                address_score = calculate_similarity(excel_address, extracted_address)\n",
    "                \n",
    "                # Calculate overall score (customize weights as needed)\n",
    "                overall_score = (name_score * 0.4) + (uid_score * 0.4) + (address_score * 0.2)\n",
    "                \n",
    "                # Determine final remarks\n",
    "                if overall_score >= 90:\n",
    "                    remarks = \"Verified\"\n",
    "                elif overall_score >= 70:\n",
    "                    remarks = \"Needs Manual Verification\"\n",
    "                else:\n",
    "                    remarks = \"Potential Fraud\"\n",
    "                \n",
    "                # Save to database\n",
    "                try:\n",
    "                    conn = get_db_connection()\n",
    "                    cursor = conn.cursor()\n",
    "                    \n",
    "                    query = \"\"\"\n",
    "                    INSERT INTO verification_results\n",
    "                    (session_id, sr_no, document_path, extracted_name, excel_name, name_match_score,\n",
    "                    extracted_uid, excel_uid, uid_match_score, extracted_address, excel_address,\n",
    "                    address_match_score, overall_score, remarks, processed_date)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    cursor.execute(query, (\n",
    "                        session['current_session'],\n",
    "                        sr_match,\n",
    "                        image_path,\n",
    "                        extracted_data.get('name', ''),\n",
    "                        record['Name'],\n",
    "                        name_score,\n",
    "                        extracted_data.get('uid', ''),\n",
    "                        str(record['UID']),\n",
    "                        uid_score,\n",
    "                        extracted_address,\n",
    "                        excel_address,\n",
    "                        address_score,\n",
    "                        overall_score,\n",
    "                        remarks,\n",
    "                        datetime.now()\n",
    "                    ))\n",
    "                    \n",
    "                    conn.commit()\n",
    "                    cursor.close()\n",
    "                    conn.close()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Database error: {str(e)}\")\n",
    "                \n",
    "                # Append to results\n",
    "                results.append({\n",
    "                    \"sr_no\": sr_match,\n",
    "                    \"document\": os.path.basename(image_path),\n",
    "                    \"name_match\": name_score,\n",
    "                    \"uid_match\": uid_score,\n",
    "                    \"address_match\": address_score,\n",
    "                    \"overall_score\": overall_score,\n",
    "                    \"remarks\": remarks\n",
    "                })\n",
    "            else:\n",
    "                # No match found in Excel\n",
    "                results.append({\n",
    "                    \"document\": os.path.basename(image_path),\n",
    "                    \"error\": \"No matching record found in Excel file\",\n",
    "                    \"extracted_data\": extracted_data\n",
    "                })\n",
    "        else:\n",
    "            # Not an Aadhaar card\n",
    "            results.append({\n",
    "                \"document\": os.path.basename(image_path),\n",
    "                \"error\": \"Not identified as an Aadhaar card\"\n",
    "            })\n",
    "    \n",
    "    # Save results to session for the results page\n",
    "    session['results'] = results\n",
    "    \n",
    "    return jsonify({\n",
    "        \"message\": \"Processing complete\",\n",
    "        \"redirect\": url_for('results_page')\n",
    "    })\n",
    "\n",
    "@app.route('/results-page')\n",
    "def results_page():\n",
    "    \"\"\"Render the results page\"\"\"\n",
    "    if 'current_session' not in session or 'results' not in session:\n",
    "        return redirect(url_for('home'))\n",
    "    \n",
    "    return render_template('results.html', results=session['results'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)  # Disable debug mode to avoid SystemExit: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe10b9-6678-45b5-9e31-252b103cf6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
